{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fader Networks: Manipulating Images by Sliding Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors attempt to disentangle facial features from images and re-generate images after tuning (fader knobs) certain continuous-valued attributes of the image like age, expression, gender etc. This is an encoder-decoder architecture.\n",
    "\n",
    "The major difference touted compared to existing methods is that adversarial training is used to learn the latent space, as opposed to the decoder output, thus, helping the latent space become invariant to the attributes (conditioning labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The attributes that are binary during train time, can be treated as continuous during image generation.\n",
    "* The dataset is pictures of actors with certain attributes, like 'smile', 'glasses', 'mouth-open' etc.\n",
    "* The architecture comprises of 3 main components, the encoder, the discriminator and the decoder.\n",
    "    * The discriminator is the adversarial component.\n",
    "* The discriminator is trained with a single objective in mind: to correct identify the attributes, given an encoded image representation\n",
    "* The encoder-decoder is trained with 2 objectives in mind:\n",
    "    1. The decoder being able to reconstruct the original input, given the encoded representation and the true attributes.\n",
    "    2. The encoded representation making it difficult for the discriminator to ascertain which attributes are present in the original image.\n",
    "* Without the adversarial component, the decoder learns to ignore the true attributes, and changing these at test time for conditioned generation makes no difference to the decoder output, which we don't want.\n",
    "* The cost attributed by the discriminator to the encoder loss is gradually increased from 0 over the course of the training.\n",
    "* The encoded image representation is generated by a convolutional network.\n",
    "* Augmentation of the face images is done by flipping the images horizontally.\n",
    "* The generated images were evaluated qualitatively and quantitatively for naturalness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The objective is to make the attributes the only source of information for the extra image attributes.\n",
    "* Avoiding having an adversarial network as part of the decoder is that backpropagation can occur even for discrete objectives, like text sequence prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
